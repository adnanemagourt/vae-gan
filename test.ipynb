{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE-GAN Architectures for Image Compression - Demo\n",
    "\n",
    "This notebook demonstrates how to use the three implemented VAE-GAN architectures for image compression:\n",
    "1. β-VAE-GAN\n",
    "2. VQ-VAE-GAN\n",
    "3. Hierarchical VAE-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "# For loading images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Models\n",
    "\n",
    "Let's load the pre-trained models for each architecture. Change the paths to where your trained models are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load β-VAE-GAN\n",
    "from beta_vae_gan.model import BetaVAEGAN\n",
    "from beta_vae_gan.config import Config as BetaConfig\n",
    "\n",
    "beta_config = BetaConfig()\n",
    "beta_model = BetaVAEGAN(beta_config)\n",
    "beta_model_path = './output/beta_vae_gan/checkpoints/best_model.pth'\n",
    "if os.path.exists(beta_model_path):\n",
    "    beta_model.load_state_dict(torch.load(beta_model_path, map_location=device))\n",
    "    beta_model = beta_model.to(device)\n",
    "    beta_model.eval()\n",
    "    print(\"β-VAE-GAN model loaded successfully\")\n",
    "else:\n",
    "    print(f\"β-VAE-GAN model not found at {beta_model_path}\")\n",
    "    beta_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VQ-VAE-GAN\n",
    "from vq_vae_gan.model import VQVAEGAN, compress_image\n",
    "from vq_vae_gan.config import Config as VQConfig\n",
    "\n",
    "vq_config = VQConfig()\n",
    "vq_model = VQVAEGAN(vq_config)\n",
    "vq_model_path = './output/vq_vae_gan/checkpoints/best_model.pth'\n",
    "if os.path.exists(vq_model_path):\n",
    "    vq_model.load_state_dict(torch.load(vq_model_path, map_location=device))\n",
    "    vq_model = vq_model.to(device)\n",
    "    vq_model.eval()\n",
    "    print(\"VQ-VAE-GAN model loaded successfully\")\n",
    "else:\n",
    "    print(f\"VQ-VAE-GAN model not found at {vq_model_path}\")\n",
    "    vq_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hierarchical VAE-GAN\n",
    "from hierarchical_vae_gan.model import HierarchicalVAEGAN, compress_hierarchical_model\n",
    "from hierarchical_vae_gan.config import Config as HierarchicalConfig\n",
    "\n",
    "hier_config = HierarchicalConfig()\n",
    "hier_model = HierarchicalVAEGAN(hier_config)\n",
    "hier_model_path = './output/hierarchical_vae_gan/checkpoints/best_model.pth'\n",
    "if os.path.exists(hier_model_path):\n",
    "    hier_model.load_state_dict(torch.load(hier_model_path, map_location=device))\n",
    "    hier_model = hier_model.to(device)\n",
    "    hier_model.eval()\n",
    "    print(\"Hierarchical VAE-GAN model loaded successfully\")\n",
    "else:\n",
    "    print(f\"Hierarchical VAE-GAN model not found at {hier_model_path}\")\n",
    "    hier_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Images\n",
    "\n",
    "Let's load some test images from the Kodak dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load an image and convert to tensor\"\"\"\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    tensor = transform(img).unsqueeze(0)\n",
    "    return img, tensor\n",
    "\n",
    "# Load a test image from Kodak dataset\n",
    "kodak_dir = './data/kodak'\n",
    "test_images = []\n",
    "test_tensors = []\n",
    "\n",
    "# Load first 4 images\n",
    "for i in range(1, 5):\n",
    "    img_path = os.path.join(kodak_dir, f'kodim{i:02d}.png')\n",
    "    if os.path.exists(img_path):\n",
    "        img, tensor = load_image(img_path)\n",
    "        test_images.append(img)\n",
    "        test_tensors.append(tensor)\n",
    "        print(f\"Loaded image {i} with shape {tensor.shape}\")\n",
    "    else:\n",
    "        print(f\"Image {i} not found at {img_path}\")\n",
    "\n",
    "# Display the test images\n",
    "if test_images:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, img in enumerate(test_images):\n",
    "        plt.subplot(1, len(test_images), i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Test Image {i+1}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression and Reconstruction with β-VAE-GAN\n",
    "\n",
    "Now let's compress and reconstruct the test images using the β-VAE-GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_with_beta_vae_gan(model, image_tensor):\n",
    "    \"\"\"Compress and reconstruct an image using β-VAE-GAN\"\"\"\n",
    "    if model is None:\n",
    "        print(\"β-VAE-GAN model not loaded\")\n",
    "        return None, None, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        # Forward pass\n",
    "        recon_x, z, mu, logvar = model(image_tensor)\n",
    "        \n",
    "        # Calculate BPP and compression ratio\n",
    "        num_elements = z.numel()\n",
    "        bits_per_element = 32  # assuming float32\n",
    "        total_bits = num_elements * bits_per_element\n",
    "        total_pixels = image_tensor.numel() / 3  # divide by 3 channels\n",
    "        bpp = total_bits / total_pixels\n",
    "        \n",
    "        original_size = image_tensor.numel() * 8  # 8 bits per channel value\n",
    "        compressed_size = total_bits\n",
    "        compression_ratio = original_size / compressed_size\n",
    "        \n",
    "        # Convert to numpy for visualization\n",
    "        original_np = image_tensor.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        recon_np = recon_x.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        return original_np, recon_np, bpp, compression_ratio\n",
    "\n",
    "# Compress and reconstruct test images\n",
    "if beta_model is not None and test_tensors:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, tensor in enumerate(test_tensors):\n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_beta_vae_gan(beta_model, tensor)\n",
    "        \n",
    "        if original_np is not None and recon_np is not None:\n",
    "            # Calculate PSNR\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            # Plot original and reconstructed\n",
    "            plt.subplot(len(test_tensors), 2, 2*i+1)\n",
    "            plt.imshow(np.clip(original_np, 0, 1))\n",
    "            plt.title(f\"Original Image {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(len(test_tensors), 2, 2*i+2)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"β-VAE-GAN: PSNR={psnr:.2f}dB, BPP={bpp:.4f}, CR={compression_ratio:.2f}x\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression and Reconstruction with VQ-VAE-GAN\n",
    "\n",
    "Now let's compress and reconstruct the test images using the VQ-VAE-GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_with_vq_vae_gan(model, image_tensor):\n",
    "    \"\"\"Compress and reconstruct an image using VQ-VAE-GAN\"\"\"\n",
    "    if model is None:\n",
    "        print(\"VQ-VAE-GAN model not loaded\")\n",
    "        return None, None, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        # Compress image\n",
    "        compressed, metadata = compress_image(model, image_tensor, device)\n",
    "        \n",
    "        # Decompress image\n",
    "        reconstructed = model.decompress_image(compressed, metadata, device)\n",
    "        \n",
    "        # Get BPP and compression ratio\n",
    "        bpp = metadata['bpp']\n",
    "        compression_ratio = metadata['compression_ratio']\n",
    "        \n",
    "        # Convert to numpy for visualization\n",
    "        original_np = image_tensor.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        recon_np = reconstructed.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        return original_np, recon_np, bpp, compression_ratio\n",
    "\n",
    "# Compress and reconstruct test images\n",
    "if vq_model is not None and test_tensors:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, tensor in enumerate(test_tensors):\n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_vq_vae_gan(vq_model, tensor)\n",
    "        \n",
    "        if original_np is not None and recon_np is not None:\n",
    "            # Calculate PSNR\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            # Plot original and reconstructed\n",
    "            plt.subplot(len(test_tensors), 2, 2*i+1)\n",
    "            plt.imshow(np.clip(original_np, 0, 1))\n",
    "            plt.title(f\"Original Image {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(len(test_tensors), 2, 2*i+2)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"VQ-VAE-GAN: PSNR={psnr:.2f}dB, BPP={bpp:.4f}, CR={compression_ratio:.2f}x\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression and Reconstruction with Hierarchical VAE-GAN\n",
    "\n",
    "Finally, let's compress and reconstruct the test images using the Hierarchical VAE-GAN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_with_hierarchical_vae_gan(model, image_tensor, bit_allocation=[8, 6, 4]):\n",
    "    \"\"\"Compress and reconstruct an image using Hierarchical VAE-GAN\"\"\"\n",
    "    if model is None:\n",
    "        print(\"Hierarchical VAE-GAN model not loaded\")\n",
    "        return None, None, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        # Simulate compression with different bit allocations\n",
    "        metrics, reconstructed, _ = compress_hierarchical_model(\n",
    "            model, image_tensor, bit_allocation=bit_allocation, device=device\n",
    "        )\n",
    "        \n",
    "        # Get BPP and compression ratio\n",
    "        bpp = metrics['bpp']\n",
    "        compression_ratio = metrics['compression_ratio']\n",
    "        \n",
    "        # Convert to numpy for visualization\n",
    "        original_np = image_tensor.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        recon_np = reconstructed.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        return original_np, recon_np, bpp, compression_ratio\n",
    "\n",
    "# Compress and reconstruct test images\n",
    "if hier_model is not None and test_tensors:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, tensor in enumerate(test_tensors):\n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_hierarchical_vae_gan(\n",
    "            hier_model, tensor, bit_allocation=[8, 6, 4]\n",
    "        )\n",
    "        \n",
    "        if original_np is not None and recon_np is not None:\n",
    "            # Calculate PSNR\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            # Plot original and reconstructed\n",
    "            plt.subplot(len(test_tensors), 2, 2*i+1)\n",
    "            plt.imshow(np.clip(original_np, 0, 1))\n",
    "            plt.title(f\"Original Image {i+1}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(len(test_tensors), 2, 2*i+2)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"Hierarchical VAE-GAN: PSNR={psnr:.2f}dB, BPP={bpp:.4f}, CR={compression_ratio:.2f}x\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Different Bit Allocations for Hierarchical VAE-GAN\n",
    "\n",
    "Let's compare the effect of different bit allocations for the hierarchical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different bit allocations to try\n",
    "bit_allocations = [\n",
    "    [8, 6, 4],  # Default - more bits for higher levels\n",
    "    [6, 6, 6],  # Equal allocation\n",
    "    [4, 6, 8],  # More bits for deeper levels\n",
    "    [10, 5, 2], # Heavy focus on highest level\n",
    "    [2, 5, 10]  # Heavy focus on deepest level\n",
    "]\n",
    "\n",
    "# Compress one test image with different bit allocations\n",
    "if hier_model is not None and test_tensors:\n",
    "    test_tensor = test_tensors[0]  # Use the first test image\n",
    "    \n",
    "    plt.figure(figsize=(20, 5 * len(bit_allocations)))\n",
    "    \n",
    "    # Plot original image\n",
    "    original_img = test_tensor.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "    plt.subplot(len(bit_allocations)+1, 3, 2)\n",
    "    plt.imshow(np.clip(original_img, 0, 1))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Compress with each bit allocation\n",
    "    for i, bits in enumerate(bit_allocations):\n",
    "        bits_str = \", \".join(map(str, bits))\n",
    "        \n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_hierarchical_vae_gan(\n",
    "            hier_model, test_tensor, bit_allocation=bits\n",
    "        )\n",
    "        \n",
    "        if original_np is not None and recon_np is not None:\n",
    "            # Calculate PSNR\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'bit_allocation': bits,\n",
    "                'psnr': psnr,\n",
    "                'bpp': bpp,\n",
    "                'compression_ratio': compression_ratio,\n",
    "                'recon_np': recon_np\n",
    "            })\n",
    "            \n",
    "            # Plot reconstructed image\n",
    "            plt.subplot(len(bit_allocations)+1, 3, (i+1)*3 + 2)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"Bits=[{bits_str}]\\nPSNR={psnr:.2f}dB, BPP={bpp:.4f}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    # Plot rate-distortion curve\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for result in results:\n",
    "        plt.scatter(result['bpp'], result['psnr'], label=f\"Bits={result['bit_allocation']}\")\n",
    "    plt.xlabel('Bits per Pixel (BPP)')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    plt.title('Rate-Distortion for Different Bit Allocations')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-Side Comparison of All Models\n",
    "\n",
    "Finally, let's compare all models side by side on the same test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models on the same test image\n",
    "if test_tensors and (beta_model is not None or vq_model is not None or hier_model is not None):\n",
    "    test_tensor = test_tensors[0]  # Use the first test image\n",
    "    \n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # Plot original image\n",
    "    original_img = test_tensor.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(np.clip(original_img, 0, 1))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # β-VAE-GAN\n",
    "    if beta_model is not None:\n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_beta_vae_gan(beta_model, test_tensor)\n",
    "        if original_np is not None and recon_np is not None:\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"β-VAE-GAN\\nPSNR={psnr:.2f}dB, BPP={bpp:.4f}, CR={compression_ratio:.2f}x\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    # VQ-VAE-GAN\n",
    "    if vq_model is not None:\n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_vq_vae_gan(vq_model, test_tensor)\n",
    "        if original_np is not None and recon_np is not None:\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"VQ-VAE-GAN\\nPSNR={psnr:.2f}dB, BPP={bpp:.4f}, CR={compression_ratio:.2f}x\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    # Hierarchical VAE-GAN\n",
    "    if hier_model is not None:\n",
    "        original_np, recon_np, bpp, compression_ratio = compress_with_hierarchical_vae_gan(\n",
    "            hier_model, test_tensor, bit_allocation=[8, 6, 4]\n",
    "        )\n",
    "        if original_np is not None and recon_np is not None:\n",
    "            mse = np.mean((original_np - recon_np) ** 2)\n",
    "            psnr = 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "            \n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(np.clip(recon_np, 0, 1))\n",
    "            plt.title(f\"Hierarchical VAE-GAN\\nPSNR={psnr:.2f}dB, BPP={bpp:.4f}, CR={compression_ratio:.2f}x\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use three different VAE-GAN architectures for image compression:\n",
    "\n",
    "1. **β-VAE-GAN**: A basic VAE-GAN with a continuous latent space, controlled by the β parameter.\n",
    "2. **VQ-VAE-GAN**: A Vector-Quantized VAE-GAN with a discrete latent space using a learned codebook.\n",
    "3. **Hierarchical VAE-GAN**: A hierarchical model with multiple levels of latent representations at different scales.\n",
    "\n",
    "Each architecture has its strengths and trade-offs in terms of reconstruction quality and compression ratio. The hierarchical model typically provides the best perceptual quality, while the VQ-VAE-GAN often achieves better compression rates.\n",
    "\n",
    "For practical applications, the choice of architecture would depend on the specific requirements of the task, including the desired balance between compression ratio, reconstruction quality, and computational resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}